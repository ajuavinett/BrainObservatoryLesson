{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are those cells doing?\n",
    "\n",
    "### This lesson will help you analyze a dataset from the Allen Brain Institute's Brain Observatory.\n",
    "\n",
    "These datasets contain calcium imaging data for various different cell types in the visual cortex of the mouse. It's likely that these cell types have different roles in the visual system -- your mission is to figure out what these roles are. You will choose a visual area, a cell type, and look at their responses to natural stimuli:\n",
    "\n",
    "<img src=\"ExperimentalDesign.png\">  \n",
    "\n",
    "### By the end of this lesson, you will be able to:\n",
    "1. Choose a dataset for a particular cell type, in a specific visual area.\n",
    "2. Plot a stimulus-response curve for one neuron.\n",
    "\n",
    "Additional information on this dataset, and how it was collected, can be found <a href=\"http://help.brain-map.org/display/observatory/Data+-+Visual+Coding\">here</a> as well as in the <a href=\"http://alleninstitute.github.io/AllenSDK/brain_observatory.html\">SDK documentation</a>. \n",
    "\n",
    "\n",
    "## Step 1. Importing toolboxes\n",
    "First, we'll import the necessary toolboxes to run this code. The first chunk of \"import\" lines will bring in some standard toolboxes that we need. For example, \"numpy\" is a toolbox that has functions to work with large arrays. The second chunk of import lines brings in some toolboxes that the Allen Brain Observatory has already packaged, to help users analyze its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Standard toolboxes\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Allen specific toolboxes\n",
    "import allensdk.brain_observatory.stimulus_info as stim_info\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "from allensdk.brain_observatory.natural_scenes import NaturalScenes\n",
    "from allensdk.brain_observatory.drifting_gratings import DriftingGratings\n",
    "\n",
    "# We will create an instance of the Brain Observatory Cache as an object, \"boc.\"\n",
    "boc = BrainObservatoryCache(manifest_file='/datasets/allen-brain-observatory/visual-coding-2p/manifest.json')\n",
    "#boc =  BrainObservatoryCache(manifest_file='boc/manifest.json')\n",
    "\n",
    "print('Successfully imported AllenSDK packages.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Get a list of all possible transgenic mouse lines and brain areas, and choose which to work with.\n",
    "Next, we'll ask that \"boc\" structure to tell us what all of the possible Cre lines and brain areas are that we can analyze. You'll need to use these exact names when you're trying to pull a specific one from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We'll save the list of cre lines as a variable, 'cre-lines'.\n",
    "cre_lines = boc.get_all_cre_lines()\n",
    "print(\"all cre lines: \" + str(cre_lines))\n",
    "\n",
    "# We'll save the list of possible structures as a variable, 'brain_areas'.\n",
    "brain_areas = boc.get_all_targeted_structures()\n",
    "print(\"all brain regions: \" + str(brain_areas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b>  Choose a visual area and Cre line from the lists above to examine in the rest of the notebook. Refer back to our lecture slides or the <a href=\"http://observatory.brain-map.org/visualcoding\">Brain Observatory landing page</a> to learn more about these different visual areas. Primary cortex (VISp) is surrounded by several other brain regions, which have unknown functions.\n",
    "    \n",
    "You can find more info about the Cre-lines here (you'll need this for your write-up) <a href=\"http://observatory.brain-map.org/visualcoding/transgenic\">here</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# put the visual area & cre line below in single quotes. e.g. 'VISp'\n",
    "visual_area = \n",
    "cre_line = \n",
    "print(\"Let's take a look at how \" + str(cre_line) + \" cells in \" + visual_area + \" respond to natural scenes. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next bit of code will get the list of all the experiment containers for that area and Cre line combination, and make a data frame so we can see what information we have on these experiments. We can use that data frame to confirm we've got the data we wanted (from the correct Cre line and structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exps = boc.get_experiment_containers(\n",
    "    targeted_structures=[visual_area],\n",
    "    cre_lines=[cre_line],)\n",
    "\n",
    "# Create a dataframe and show us the beginning of it\n",
    "# If there aren't experiments with that combination, you'll get an error message.\n",
    "exps_df = pd.DataFrame(exps)\n",
    "if exps_df.empty:\n",
    "    print('There are not any experiments for that cre-driver line and visual area combination.')\n",
    "    print('Change either/and your visual_area and cre_line in the code above, and re-run.')\n",
    "\n",
    "print('All experiments for' + str(cre_line) + \" cells in \" + visual_area + ': ')\n",
    "exps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b>  Pick an experiment from the table above. Copy the id in the \"id\" column and save it as a variable \"experiment_container_id\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment_container_id = \n",
    "print(experiment_container_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll get information about all of the experiment sessions in your experiment container.  This is accomplished with the `get_ophys_experiments` method. Most experiments have three different sessions, for different types of visual stimuli.\n",
    "\n",
    "<b>Note</b>: This step could take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "expt_cont = boc.get_ophys_experiments(experiment_container_ids=[experiment_container_id],\n",
    "                                      stimuli=['natural_scenes'])\n",
    "session_id = expt_cont[0]['id']\n",
    "data_set = boc.get_ophys_experiment_data(ophys_experiment_id=session_id)\n",
    "print('Data acquired for session '+str(session_id))\n",
    "pd.DataFrame(expt_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Download & inspect the natural scenes imaging session\n",
    "First, we'll look at the session where the mouse viewed natural scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the data you just acquired. We'll take a maximum projection of the data, so that we can actually see the cells. If we just looked at one snapshot of the raw imaging data, the cells would look dim. A \"maximum projection image\" shows us the maximum brightness for each pixel, across the entire experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_projection = data_set.get_max_projection()\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(max_projection, cmap='gray')\n",
    "plt.ylabel('\\u03BCm',fontsize=14)\n",
    "plt.xlabel('\\u03BCm',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see our cells in action! First, we need to prepare a few things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "raw_data_dir = '/datasets/allen-brain-observatory/visual-coding-2p/ophys_movies/'\n",
    "def get_raw_data_path(session_id):\n",
    "    return os.path.join(raw_data_dir, 'ophys_experiment_'+str(session_id)+'.h5')\n",
    "\n",
    "exp_path = get_raw_data_path(session_id)\n",
    "raw_data = h5py.File(exp_path, 'r')\n",
    "raw_data['data']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "im = ax.imshow(raw_data['data'][0])\n",
    "ax.axis('off')\n",
    "\n",
    "def init():\n",
    "    im.set_data(raw_data['data'][0])\n",
    "    return (im,)\n",
    "\n",
    "def animate(i):\n",
    "    im.set_data(raw_data['data'][i])\n",
    "    return (im,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=30, interval=1000./30, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually play the animation. Run the code below & press play. <b>Note</b> this might take a few seconds to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Look at the calcium transients of your cells\n",
    "\n",
    "Now we'll plot the data of each of our cells (from the field of view above) across time. Each line shows the change in fluorescence over baseline (deltaF/F) of the individual cells. When there are sharp increases in the gray lines, that's when the cells are responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts, dff = data_set.get_dff_traces()\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "for i in range(50):\n",
    "    plt.plot(dff[i]+(i*2), color='gray')\n",
    "    plt.xlabel('frames',fontsize=14)\n",
    "    plt.ylabel('cell #',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b> Choose one cell to look at. The plot above gives you an idea of how many cells there are. Save your cell number as a variable \"my_cell.\"</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose a number somewhere between 0 and the # cells above\n",
    "my_cell = \n",
    "cell_specimen_ids = data_set.get_cell_specimen_ids()\n",
    "cell_id = cell_specimen_ids[1]\n",
    "\n",
    "# get raw traces for that cell & plot\n",
    "time, single_dff = data_set.get_dff_traces(cell_specimen_ids=[cell_id])\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(time[:1000], single_dff[0,:1000])\n",
    "plt.xlabel('frames')\n",
    "plt.ylabel('\\u0394F/F',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Look at the response of your cell to natural scenes\n",
    "Hmm, there are some responses above, but it's tough to see what's going on with just the raw traces. Let's instead see how these cells actually responded to different types of images.\n",
    "\n",
    "First, we'll organize the stimulus table. This tells us which stimulus was played on each trial. This data set has 118 different scenes, and each scene is presented 50 times. Images of the scenes can be found here: http://observatory.brain-map.org/visualcoding/stimulus/natural_scenes\n",
    "\n",
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b> Choose one of the natural scenes (there are 118 total). Put next to \"image_id\" below. Try another one if you're not happy with your first random choice.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#choose your image id\n",
    "image_id = \n",
    "\n",
    "natural_scene_table = data_set.get_stimulus_table('natural_scenes')\n",
    "natural_scene_template = data_set.get_stimulus_template('natural_scenes')\n",
    "sceneIDs = np.unique(natural_scene_table.frame)\n",
    "\n",
    "# plot this natural scene\n",
    "plt.imshow(natural_scene_template[image_id,:,:], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll find all of the cells that significantly prefer this stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the experiment_container id for this session\n",
    "this_expt = expt_cont['id'==session_id]\n",
    "experiment_container_id = this_expt['experiment_container_id']\n",
    "cell_specimens = pd.DataFrame(boc.get_cell_specimens())\n",
    "subset = cell_specimens[cell_specimens.experiment_container_id==experiment_container_id]\n",
    "sig_subset = subset[(subset.p_ns<0.05)&(subset.pref_image_ns==image_id)].cell_specimen_id\n",
    "\n",
    "if sig_subset.empty:\n",
    "    print('No cells in this experiment significantly preferred your stimulus!')\n",
    "    print('Change the image ID, and re-run.')\n",
    "else:\n",
    "    print('Cell specimen IDs:')\n",
    "    print(sig_subset.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data of single trials where a single cell was shown your images above.\n",
    "<p>\n",
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b> Choose one of the cell specimen IDs from above and enter it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_id = \n",
    "ts, dff = data_set.get_dff_traces()\n",
    "cell_index = data_set.get_cell_specimen_indices([cell_id])[0]\n",
    "\n",
    "stim_subset = natural_scene_table[natural_scene_table.frame==image_id]\n",
    "for i in range(len(stim_subset)):\n",
    "    plt.plot(dff[cell_index,stim_subset.start.iloc[i]-10:stim_subset.end.iloc[i]+10], color='gray')\n",
    "plt.axvspan(10,18, color='red',alpha=0.2)\n",
    "plt.ylabel('\\u0394F/F',fontsize=14)\n",
    "plt.xlabel('frames',fontsize=14)\n",
    "plt.title('Single trial responses to selected natural scene')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, a few cells in your dataset like this particular image, but what about all of the cells? And what about all of the other images? To visualize this, we'll plot a histogram of how many cells significantly prefer certain images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "axes = subset[(subset.p_ns<0.05)].pref_image_ns.plot(kind=\"hist\",fc=(0, .5,.5, 0.5),bins=117)\n",
    "axes.set_ylabel('# cells that preferred image',fontsize=14)\n",
    "axes.set_xlabel('image id',fontsize=14)\n",
    "axes.set_xlim(1,117.5)\n",
    "plt.show()\n",
    "\n",
    "n, bins, patches = axes.hist(subset[(subset.p_ns<0.05)].pref_image_ns, 117, density=1)\n",
    "\n",
    "print('Top image is '+str(n.argmax()+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which images do the cells in your experiment actually respond to? Scroll back up to the block where you plotted your first preferred image and change the image ID so that you can see what the image actually is.\n",
    "\n",
    "<b>Save the histogram above for your lab write-up.<b/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Examine the direction selectivity of your cell\n",
    "Sometimes, the function of a cell is not particularly clear from natural stimuli. Those stimuli have a lot of information in them, and it might be hard to tell what a cell is actually responding to. Instead, we can use simple drifting gratings to look at one straightforward property of a cell: <b>does it respond to specific directions of movement?</b></br>\n",
    "\n",
    "We'll take the same cell you looked at above, but look at its response to drifting gratings. Below, we'll plot the response of this cell to different directions of the grating.\n",
    "\n",
    "First, let's look at the raw data in response to a single stimulus. The code below will plot several seconds of data during a drifting grating. The stimulus was played while the background of the plot is gray.\n",
    "\n",
    "<p>\n",
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b> Beginning with stim_id = 0, look for a stimulus that drives this cell to become more active. If there isn't a clear response during the stimulus, increase the number next to \"stim_id\" until you find one. You want to see <i>some</i> change between the baseline (beginning) and gray shaded (stimulus) period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# change the stim_id below to find a good response\n",
    "stim_id = 0\n",
    "drifting_exps = boc.get_ophys_experiments(cell_specimen_ids=[cell_id],\n",
    "                stimuli=['drifting_gratings'],targeted_structures=[visual_area],\n",
    "                cre_lines=[cre_line])\n",
    "drifting_id = drifting_exps[0]['id']\n",
    "drifting_data = boc.get_ophys_experiment_data(drifting_id)\n",
    "\n",
    "if drifting_data.get_dff_traces(cell_specimen_ids=[cell_id]):\n",
    "    timestamps, dff = drifting_data.get_dff_traces(cell_specimen_ids=[cell_id])\n",
    "else:\n",
    "    timestamps, dff = drifting_data.get_dff_traces()\n",
    "    \n",
    "dff_trace = dff[0,:]\n",
    "stim_table = drifting_data.get_stimulus_table('drifting_gratings')\n",
    "\n",
    "plt.plot(dff_trace[stim_table.start[stim_id]-30:stim_table.end[stim_id]+30])\n",
    "plt.axvspan(30,90, color='gray', alpha=0.3) #this shades the period when the stimulus is being presented\n",
    "plt.ylabel('\\u0394F/F',fontsize=14)\n",
    "plt.xlabel('frames',fontsize=14)\n",
    "plt.title('response to '+ str(stim_table.orientation[stim_id])+' degrees',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the response to one stimulus -- it might be quite noisy (or you might have found a good one!). If there isn't a clear response (if the trace doesn't rise when the stimulus comes on) change the stim_id in the code above and re-run. Once you've found a clear response, <b>save the image for your lab write-up</b>.\n",
    "\n",
    "Next, let's look across all directions of the stimulus, to see if we can find any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_response= np.zeros((len(stim_table),3))\n",
    "for i in range(len(stim_table)):\n",
    "    cell_response[i,0] = stim_table.orientation[i]\n",
    "    cell_response[i,1] = stim_table.temporal_frequency[i]\n",
    "    cell_response[i,2] = dff_trace[stim_table.start[i]:stim_table.end[i]].mean()\n",
    "    \n",
    "all_ori = np.unique(cell_response[:,0])\n",
    "orivals = all_ori[np.isfinite(all_ori)]\n",
    "np.sort(stim_table.orientation.dropna().unique())\n",
    "tfvals = np.unique(cell_response[:,1])\n",
    "tfvals = tfvals[np.isfinite(tfvals)]\n",
    "tuning_array = np.empty((8,5))\n",
    "\n",
    "for i,ori in enumerate(orivals):\n",
    "    for j,tf in enumerate(tfvals):\n",
    "        trials = np.where(np.logical_and(cell_response[:,0]==ori, cell_response[:,1]==tf))[0]\n",
    "        tuning_array[i,j] = cell_response[trials,2].mean()\n",
    "for i in range(5):\n",
    "    plt.plot(orivals, tuning_array[:,i], 'o-')\n",
    "    plt.xlabel('direction of stimulus',fontsize=14)\n",
    "    plt.ylabel('\\u0394F/F',fontsize=14)\n",
    "    plt.title('Direction selectivity',fontsize=14)\n",
    "    plt.legend(tfvals,title='Speed (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different colors here denote different speeds of the stimulus. It's also possible your cell is selective for a specific stimulus speed! \n",
    "\n",
    "Is your cell direction selective? In other words, does it clearly respond to one orientation over other orientations? It may also be orientation selective -- responding to two, opposite directions.\n",
    "\n",
    "<b>Save this plot for your Canvas write-up.</b>\n",
    "\n",
    "We can take a look at the data for this cell to see if there is a clear direction or orientation selectivity index (dsi or osi selectively). Not all cells have this information, but let's look at the table to see if yours does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_data = subset[subset.cell_specimen_id==[cell_id]]\n",
    "cell_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all folks. Submit your write-up on Canvas to get your points for the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML('<img src=\"https://i.chzbgr.com/full/5107765760/h244F968D/\">')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
